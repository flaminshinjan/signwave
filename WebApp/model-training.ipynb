{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/shinjanpatra/Desktop/signwave/WebApp/model_task/gesture_recognizer.task\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W20230418 06:46:23.240134 43086464 gesture_recognizer_graph.cc:121] Hand Gesture Recognizer contains CPU only ops. Sets HandGestureRecognizerGraph acceleartion to Xnnpack.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "GestureRecognizer = mp.tasks.vision.GestureRecognizer\n",
    "GestureRecognizerOptions = mp.tasks.vision.GestureRecognizerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "# Create a gesture recognizer instance with the video mode:\n",
    "options = GestureRecognizerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.VIDEO)\n",
    "# with GestureRecognizer.create_from_options(options) as recognizer:\n",
    "\n",
    "recognizer = GestureRecognizer.create_from_options(options)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "at(): incompatible function arguments. The following argument types are supported:\n    1. (self: mediapipe.python._framework_bindings.packet.Packet, arg0: int) -> mediapipe.python._framework_bindings.packet.Packet\n    2. (self: mediapipe.python._framework_bindings.packet.Packet, arg0: mediapipe.python._framework_bindings.timestamp.Timestamp) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: <mediapipe.Packet with timestamp: UNSET and C++ type: ::mediapipe::Image>, 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     10\u001b[0m mp_image \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39mImage(image_format\u001b[39m=\u001b[39mmp\u001b[39m.\u001b[39mImageFormat\u001b[39m.\u001b[39mSRGB, data\u001b[39m=\u001b[39mimg)\n\u001b[0;32m---> 12\u001b[0m recognizer\u001b[39m.\u001b[39;49mrecognize_async(mp_image, timestamp)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/layer0/lib/python3.10/site-packages/mediapipe/tasks/python/vision/gesture_recognizer.py:425\u001b[0m, in \u001b[0;36mGestureRecognizer.recognize_async\u001b[0;34m(self, image, timestamp_ms, image_processing_options)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39m\"\"\"Sends live image data to perform gesture recognition.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \n\u001b[1;32m    393\u001b[0m \u001b[39mThe results will be available via the \"result_callback\" provided in the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[39m  gesture recognizer has already processed.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    421\u001b[0m normalized_rect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_to_normalized_rect(\n\u001b[1;32m    422\u001b[0m     image_processing_options, roi_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    423\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send_live_stream_data({\n\u001b[1;32m    424\u001b[0m     _IMAGE_IN_STREAM_NAME:\n\u001b[0;32m--> 425\u001b[0m         packet_creator\u001b[39m.\u001b[39;49mcreate_image(image)\u001b[39m.\u001b[39;49mat(\n\u001b[1;32m    426\u001b[0m             timestamp_ms \u001b[39m*\u001b[39;49m _MICRO_SECONDS_PER_MILLISECOND),\n\u001b[1;32m    427\u001b[0m     _NORM_RECT_STREAM_NAME:\n\u001b[1;32m    428\u001b[0m         packet_creator\u001b[39m.\u001b[39mcreate_proto(normalized_rect\u001b[39m.\u001b[39mto_pb2())\u001b[39m.\u001b[39mat(\n\u001b[1;32m    429\u001b[0m             timestamp_ms \u001b[39m*\u001b[39m _MICRO_SECONDS_PER_MILLISECOND)\n\u001b[1;32m    430\u001b[0m })\n",
      "\u001b[0;31mTypeError\u001b[0m: at(): incompatible function arguments. The following argument types are supported:\n    1. (self: mediapipe.python._framework_bindings.packet.Packet, arg0: int) -> mediapipe.python._framework_bindings.packet.Packet\n    2. (self: mediapipe.python._framework_bindings.packet.Packet, arg0: mediapipe.python._framework_bindings.timestamp.Timestamp) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: <mediapipe.Packet with timestamp: UNSET and C++ type: ::mediapipe::Image>, 0.0"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# timestamp = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=img)\n",
    "    \n",
    "    recognizer.recognize_async(mp_image, timestamp)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('layer0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a75905dc6b0543bda86efc138049a84a43199cfe8b030c81ffe1011a155e2dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
